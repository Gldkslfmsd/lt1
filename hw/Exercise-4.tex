%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\usepackage{listings}
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
%\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

\usepackage{xcolor,colortbl}
\definecolor{Gray}{gray}{0.85}

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\vspace{-1.1cm}
\normalfont \normalsize 
\textsc{Language Technology I, Winter 2016-2017} \\ [25pt] % Your university, school and/or department name(s)
%\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Exercise 4: N-grams \\ % The assignment title
%\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

%\author{John Smith} % Your name

\date{} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\vspace{-2cm}
\textit{You can earn up to 20 points on this exercise.\\
You may work as a group of up to 3 people, but please submit your own version.
}\\

\textit{Please email your solution to} \texttt{langtech1saarlandws1617@gmail.com} by \textbf{15:00, November 23, 2015}. \textit{Use the subject line ``Exercise 4'' (there was no Exercise 3), and attach an answer PDF file as well as the model file requested in Task 2. (Some of the following tasks \textbf{may} have been blatantly copied from Statistical Machine Translation book available here: \url{http://www.statmt.org/book/} We didn't check.)} \\

%\vspace{3cm)
\section*{Task 1}
Consider the following Mother Goose nursery rhyme, without case or
punctuation (it is a string of words).  This is our corpus.
\begin{center}
\begin{quotation}
$<$s$>$ peter piper picked a peck of pickled peppers $<$/s$>$\\
$<$s$>$ a peck of pickled peppers peter piper picked $<$/s$>$\\
$<$s$>$ if peter piper picked a peck of pickled peppers $<$/s$>$\\
$<$s$>$ where s the peck of pickled peppers peter piper picked $<$/s$>$
\end{quotation}
\end{center}

\begin{enumerate}
\item Construct and show a table of probabilities for observed
  bigrams, including the start and end symbols, given the above
  corpus. (2 points)
\item Construct and show a count-of-counts table for the bigrams. (2 points)
\item Adjust and show the bigram table using Good-Turing discounting.
  Use add-one smoothing on the count-of-counts table if there are
  missing counts. (2 points)
\item Give the probability of a missing bigram. (1 point)
\item Briefly explain in your own words the purpose of smoothing the
  count-of-counts table. (1 point)
\end{enumerate}

\section*{Task 2}
This exercise is to get you to used to using NLTK and Python for doing
common text processing tasks.  

\begin{enumerate}
\item Download the sample training and test texts posted on the web site.
\item Write a Python script that uses NLTK's Punkt sentence tokenizer
  and the WordPunctTokenizer to turn the posted sample texts into
  files with the following characteristics: one sentence per line, each
  line lowercased and tokenized.  Use default values for the tokenizers.
\item Submit the script you used to do this (3 points).
\item Report the total numbers of lines and tokens you get from 
  processing the training and test corpora, each file separately (2 points).
\end{enumerate}

\section*{Task 3}
This exercise is to get you familiar with using a popular LM
toolkit. Download and install the
SRILM\footnote{\url{http://www.speech.sri.com/projects/srilm/download.html}}
 toolkit. SRILM is a great free language modelling toolkit for doing
various n-gram language models. It
includes several other smoothing techniques, but today we will use Good-Turing 
and Laplace.
\begin{enumerate}
\item Train the following models on the training set:
  \begin{enumerate}
    \item Order-2 SRILM Good-Turing discounted model.
    \item Order-3 SRILM Good-Turing discounted model.
    \item Order-4 SRILM Good-Turing discounted model.
    \item Order-3 SRILM Laplace smoothing model adding 1.
    \item Order-3 SRILM Laplace smoothing model adding 0.001.
  \end{enumerate}
  Attach the order-2 model with your submission. (1 point)
\item Report the perplexity for each model on the test corpus with and 
  without end-of-sentence tags. (2 points)
\item Explain in your own words the differences between the
  perplexities of the order 2, 3, and 4 Good-Turing discounted
  models. What happens as you increase the order, and why? (2 points)
\item Explain in your own words the differences between the
  perplexities of the default Good-Turing order 3 model, the model
  with add-1, and the model with add 0.001.  What happens as you
  change the added constant? (2 points)
\end{enumerate}


\end{document}
